{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *“Why Should I Trust You?”*\n",
    "# Explaining the Predictions of Any Classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION\n",
    "\n",
    "### 머신러닝 기술이 발달함에 따라 사람의 역할이 간과되는 경향이 종종 있지만,\n",
    "### 여전히 어떤 작업을 수행하는데 사람의 역할은 매우 중요합니다.\n",
    "\n",
    "<br>\n",
    "- ### 믿음의  관점 1\n",
    "\n",
    "> ### 성능 좋은 Black Box 모델은 많습니다.\n",
    "> ### 하지만 이는 실용화 관점에서 많은 문제점이 되고있습니다.\n",
    "> ### 모델을 이용하는 사람은 모델을 이해하지 못하면 사용하지 않으며,\n",
    "> ### 대부분의 의사결정자들은 머신러닝 전공자가 아닙니다.\n",
    "> ### 실전에서는 모델의 신뢰도에 대한 측도를 만드는 것도 모델러의 일이며,\n",
    "> ### 이 측도는 사람에게 설명 가능한 공간에서도 필요합니다.\n",
    "> ### 모델의 설명력도 성능만큼이나 중요합니다.\n",
    "\n",
    "<br>\n",
    "- ### 믿음의 관점 2\n",
    "\n",
    "> ### 설명력이 있는 모델은 개선하기도 수월하고 응용하기도 쉽습니다.\n",
    "> ### 모델의 예측은 통계적으로 안정적일 지 모르나,\n",
    "> ### 이는 어디까지나 개발 과정에서일 뿐이지 실제 배포 환경에서는 알 수 없는 일입니다.\n",
    "> ### 배포 환경에서 생긴 문제를 설명력 없는 모델에서 제대로 해결하는 것은 매우 어려운 일입니다.\n",
    "\n",
    "<br>\n",
    "- ### CONTRIBUTIONS\n",
    "\n",
    "> ### 이 논문에서는 모델에 대한 믿음과 설명의 시도를\n",
    "> ### 모델의 각 예측에 대해 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLANATIONS\n",
    "\n",
    "![](./img/1.png)\n",
    "\n",
    "- ### 모델은 환자가 독감을 앓고 있다고 말합니다.\n",
    "- ### LIME(해석 모델)은 이중 해당 환자가 독감이라고 예측한 이유가 된 주요 요인을 강조해 보여줍니다.\n",
    "- ### 의사(전문가)는 이 해석 결과의 도움을 받습니다.\n",
    "\n",
    "![](./img/2.png)\n",
    "\n",
    "- ### RBF 커널트릭을 이용한 서포트 백터 머신으로 만들어진 두 모델을 비교합니다.\n",
    "- ### 양측의 모델 모두 높은 성능을 보이지만,\n",
    "- ### 오른쪽 모델의 해석 결과는 모델이 심각하게 잘못되었음을 알려줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLAINERS\n",
    "\n",
    "### 이상적인 설명모델에 대한 몇가지 조건을 나열합니다.\n",
    "\n",
    "<br>\n",
    "- ### 이해 가능해야합니다.\n",
    "> ### 실제 모델에서 이용된 Feature 공간과 이해 가능한 공간은 차이가 있을 수 있습니다.\n",
    "> ### 이로 인해 설명모델은 실제 모델과 차이를 생길 수도 있습니다.\n",
    "\n",
    "<br>\n",
    "- ### Local Fidelity\n",
    "![](./img/3.png)\n",
    "> ### 설명모델은 이해 가능한 정도로 축소됩니다.\n",
    "> ### 결과적으로 원래 모델의 전역적 원리를 완벽히 설명하지 못할 수 있습니다.\n",
    "> ### 하지만 설명은 지역적인 관점에서라도,\n",
    "> ### 이해 되며 신뢰할수 있을 정도여야 합니다.\n",
    "\n",
    "<br>\n",
    "- ### Model-Agnostic\n",
    "> ### 확장성이 있어야 합니다\n",
    "> ### 어떤 모델이라도 상관 없이 설명력을 부여할 수 있어야합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME (Local Interpretable Model-Agnostic Explanations)\n",
    "\n",
    "- ### Feature => Interpretable Representation\n",
    "> ### 텍스트 분석을 예로 들면,\n",
    "> ### 대표적으로 각각의 단어가 있는지 없는지를 해석 가능한 공간(표현)으로 볼 수 있습니다.\n",
    "![](./img/5.png)\n",
    "![](./img/6.png)\n",
    "- ### Fidelity-Interpretability Trade-off\n",
    "\n",
    "### G는 가능한 모든 해석의 집합\n",
    "![](./img/9.png)\n",
    "### f는 확률을 출력하는 원 모델\n",
    "![](./img/7.png)\n",
    "### 우항의 첫번째 요소는 모델의 불신 정도\n",
    "### 우항의 두번째 요소는 모델의 복잡함 정도\n",
    "- ### 의사결정 나무의 경우 나무의 깊이, 다중선형회귀의 경우 계수의 수 등...\n",
    "\n",
    "![](./img/8.png)\n",
    "\n",
    "### 파이는 거리 측도\n",
    "\n",
    "![](./img/5.png)\n",
    "![](./img/6.png)\n",
    "\n",
    "### x에서 0이 아닌 부분중에 Sampling\n",
    "\n",
    "![](./img/10.png)\n",
    "![](./img/11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편의상 가정\n",
    "- ### 선형 회귀로 표현\n",
    "![](./img/12.png)\n",
    "- ### 거리 측도는 다음을 이용\n",
    "![](./img/13.png)\n",
    "\n",
    "(cosine distance for text, L2 distance for images)\n",
    "\n",
    "![](./img/18.png)\n",
    "\n",
    "![](./img/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 복잡도\n",
    "\n",
    "- ### 텍스트: k개의 단어\n",
    "- ### dlalwl: 슈퍼픽셀\n",
    "\n",
    "![](./img/14.png)\n",
    "\n",
    "![](./img/15.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/16.png)\n",
    "![](./img/17.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
