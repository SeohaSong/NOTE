{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP COMPRESSION:\n",
    "# COMPRESSING DEEP NEURAL NETWORKS WITH PRUNING, TRAINED QUANTIZATION AND HUFFMAN CODING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 기반 알고리즘들은 시간복잡도와 공간복잡도 모두 높은 경향이 있습니다.\n",
    "\n",
    "### 따라서 컴퓨팅 자원이 제한된 임배디드 시스템에 실제 상품으로 이용되기 어렵습니다.\n",
    " \n",
    "### 본 논문은 Deep Compression을 수행해 이러한 문제점을 해결하고자 하며\n",
    "\n",
    "### 이를 위해 다음 세가지 방법론을 이용합니다.\n",
    "\n",
    "![](./img/1.png)\n",
    "\n",
    "- ### Pruning\n",
    "- ### Trained Quantization\n",
    "- ### Huffman Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이로 인해 신경망 모델을 저장하는 저장소의 용량은 모델의 정확도를 유지하면서 35배에서 49배까지 줄였습니다.\n",
    "\n",
    "- ### Pruning은 9배에서 13배까지 노드간의 연결을 줄입니다\n",
    "- ### Quantization은 연결의 정밀도를 32비트에서 5비트로 줄입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 본 논문의 방법론은 ImageNet 데이터셋에서\n",
    "### AlexNet을 35배까지 (240MB => 6.9MB) 정확도 손실 없이 작게 만들었습니다.\n",
    "### VGG-16을 49배까지 (552MB => 11.3MB) 정확도 손실 없이 작게 만들었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이러한 모델 용량의 감소는 모델을\n",
    "\n",
    "- ### 저장소 관점에서\n",
    "    - ### 반도체 외부에 위치하는 DRAN에서 동작하는게 아닌\n",
    "    - ### 반도체 내부에 위치하는 SRAM에서 동작할 수 있게 해주며\n",
    "    \n",
    "- ### 대역폭 관점에서\n",
    "    - ### 한정된 대역폭에서 효율적으로 모델에 접근할 수 있게 해줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU, GPU, 모바일 기기 GPU 세 환경에서 압축된 모델들은 \n",
    "### 3배에서 4배 빠른 속도와 3배에서 7배 높은 에너지 효율을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모바일 기반 시장은 용량에 민감합니다.\n",
    "\n",
    "#### ex) 어플리케이션의 용량이 100MB가 넘을 경우 앱스토어는 와이파이 연결이 있을때만 다운로드 되도록 권유하기도 합니다.\n",
    "\n",
    "### 상상해보세요!\n",
    "### 100메가 짜리 스마트 어플과 같은 기능을 하는데 10메가짜리 어플을 다운받을 때의\n",
    "### 당신은 무슨 생각을 할까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그럼에도 불구하고 딥러닝 기반 모델들은 모바일에 위치할 필요가 있습니다.\n",
    "### 모바일에 모델이 직접 위치한다면\n",
    "- ### 더 낮은 네트워크 비용\n",
    "- ### 이로 인한 더 나은 개인정보 보호\n",
    "- ### 더 빠른 프로세스 속도 등 많은 장점을 가질 수 있습니다.\n",
    "### 하지만 큰 저장소 용량을 요구하는 딥러닝 모델의 특징 때문에 산업에서 딥러닝 모델은 모바일에 설치되지 못하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사실 저장소 뿐만이 아닙니다. 모바일 시장은 에너지효율에도 민감합니다.\n",
    "### 큰 모델은 큰 수준의 메모리 관리를 요구하게 되고\n",
    "### 모델이 크도록 만드는 원인이 되는 많은 파라미터들은 많은 계산량을 요구합니다\n",
    "\n",
    "### 많은 자원을 요구하는 컴퓨팅은 에너지 효율도 낮습니다.\n",
    "### 낮은 에너지 효율의 모델은 모바일 기기에 위치하기 힘듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모바일 기기에서 거의 대부분의 에너지는 메모리 엑세스에 이용됩니다.\n",
    "\n",
    "### 예를들어 32비트의 소수점을 더하는 연산을 수행할 경우 다음의 3단계 작업을 거치게 됩니다.\n",
    "\n",
    "- ### 32비트 소수점 더하기 연산 (0.9pJ)\n",
    "- ### 32비트에 해당하는 SRAM 캐시 엑세스 (5pJ)\n",
    "- ### 32비트에 해당하는 DRAM 메모리 엑세스 (650pJ)\n",
    "\n",
    "![](./img/2.png)\n",
    "\n",
    "### 딥러닝 모델이 DRAM에 위치하게 되면 에너지 효율은 모바일 기기가 감당할수 있는 수준을 넘어서게 됩니다.\n",
    "### 딥러닝 모델이 SRAM에 위치하기 위해서는 모델의 크기가 작아져야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK PRUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네트워크 가지치기는 CNN 분야에서 광범위하게 논의되오던 방법론입니다.\n",
    "### 가지치기는 모델의 복잡도를 줄여주고 결과적으로 오버피팅될 확률을 낮춘다는 연구 결과가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 본 논문의 저자는 2015년 논문에서 SOTA의 가지치기 된 정확도를 유지한 CNN을 만들어 낸 바 있습니다.\n",
    "\n",
    "![](./img/3.png)\n",
    "\n",
    "### 방식은 간단합니다.\n",
    "\n",
    "### 1. 네트워크를 학습하고\n",
    "### 2. 기준점 이하의 작은 연결을 제거한 뒤에 다시 네트워크를 학습시킵니다.\n",
    "### 3. 이렇게 9배에서 13배 정도로 파라미터 수를 줄입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연결의 제거는 파라미터를 0으로 만들어 수행합니다.\n",
    "### 이렇게 되면 CNN의 경우 Sparse한 행렬이 만들어지며\n",
    "### 이행렬을 그대로 저장하는 것은 압축의 큰 효과를 볼 수 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 따라서 다음과 같은 조치를 취해줍니다.\n",
    "### [위키](https://ko.wikipedia.org/wiki/%ED%9D%AC%EC%86%8C%ED%96%89%EB%A0%AC)\n",
    "![](./img/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINED QUANTIZATION AND WEIGHT SHARING\n",
    " \n",
    "#### (한국어로 양자화라고 부르도록 하겠습니다)\n",
    "\n",
    "### 두번째 압축 기법으로 양자화를 수행합니다. 다음 그림으로 설명 가능합니다.\n",
    "\n",
    "![](./img/5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이처럼 압축을 시행할 경우 값으로서 저장해야 할 비트 크기가 줄어듭니다.\n",
    "\n",
    "### 이때 가중치의 종류를 정하고 싶은 만큼 제한하여 각각의 가중치들이 같은 메모리 주소를 참조하도록 설정합니다.\n",
    " \n",
    "### 군집 수 k개 기준 압축률 계산 식은 다음 과 같습니다.\n",
    "\n",
    "![](./img/6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEIGHT SHARING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웨이트가 될 요소들은 단순 K-근접 군집화 기법을 이용해 구합니다.\n",
    "\n",
    "### WCSS (Within-cluster Sum of Square)\n",
    "\n",
    "![](./img/7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웨이트가 될 요소들을 구하는 K-근접 군집화 알고리즘은\n",
    "\n",
    "### 초기의 Centroid값을 어떻게 설정하는지에 따라서 결과가 많이 달라집니다.\n",
    "\n",
    "### 본 논문에서는 3가지 방식으로 초기 설정을 해 보았습니다.\n",
    "\n",
    "- ### Forgy\n",
    "    - #### 무작위\n",
    "- ### Density-based\n",
    "    - #### 가중치의 분포의 CDF 공간을 구간을 쪼개며 깁스샘플링\n",
    "- ### Linear\n",
    "    - #### 가중치의 Min과 Max구간에서 구간을 쪼개서 분배\n",
    "\n",
    "![](./img/9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEED-FORWARD AND BACK-PROPAGATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/11.png)\n",
    "![](./img/10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HUFFMAN CODING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
