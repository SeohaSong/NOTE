{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Style Transfer Using Convolutional Neural Networks (2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지의 본래 내용을 유지하면서 스타일만 바꾸는 작업은 어려운 축에 속하는 작업입니다.\n",
    "\n",
    "### 논란의 여지가 있지만, 이 논문 이전의 접근법들은 이미지의 내용이라는 요소와 스타일이라는 요소를 명확히 분리하지 못했습니다.\n",
    "\n",
    "### 이 논문에서는 CNN을 이용해 명확히 두 요소를 분리하고자 합니다.\n",
    "\n",
    "> 서로 다른 스타일로 이미지의 의미 내용을 렌더링하는 것은 어려운 이미지 처리 작업입니다.<br>\n",
    "논란의 여지가 있지만, 이전 접근법의 주요 제한 요소는 의미 정보를 명시 적으로 표현하는 이미지 표현이 부족하여 스타일과 이미지 콘텐츠를 분리 할 수있게하는 것이 었습니다.<br>\n",
    "여기서 우리는 객체 인식을 위해 최적화 된 컨볼 루션 뉴럴 네트워크 (Convolutional Neural Networks)에서 파생 된 이미지 표현을 사용하여 높은 수준의 이미지 정보를 명확하게합니다.<br>\n",
    "우리는 자연스러운 이미지의 이미지 콘텐트와 스타일을 분리하고 재결합 할 수있는 Artistic Style의 Neural Algorithm을 소개합니다.<br>\n",
    "알고리즘을 통해 우리는 임의의 사진의 내용과 잘 알려진 수많은 작품의 외관을 결합한 높은 지각 품질의 새로운 이미지를 제작할 수 있습니다.<br>\n",
    "우리의 결과는 컨볼 루션 뉴럴 네트워크 (Convolutional Neural Networks)에서 배운 깊은 이미지 표현에 대한 새로운 통찰력을 제공하고 높은 수준의 이미지 합성 및 조작 가능성을 입증합니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한 이미지에서 다른 이미지로 그 스타일을 적용하는 것을 텍스처 전송이라고 부를 수 있습니다.\n",
    "\n",
    "### 기존에 있는 많은 방법들은 이미지 합성을 본래의 내용이 회손되지 않도록 제한하는 한에서 수행하는 매커니즘을 따릅니다.\n",
    "\n",
    "### 기존에 있는 많은 방법들은 비모수적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 한 이미지에서 다른 이미지로 스타일을 전송하는 것은 텍스처 전송의 문제로 간주 될 수 있습니다.<br>\n",
    "텍스처 전송에서 목표는 대상 이미지의 의미 내용을 보존하기 위해 텍스처 합성을 제한하면서 소스 이미지에서 텍스처를 합성하는 것입니다.<br>\n",
    "텍스처 합성에는 주어진 소스 텍스처의 픽셀을 리샘플링하여 사실적 자연 텍스처를 합성 할 수있는 강력한 비모수 적 알고리즘이 많이 있습니다.<br>\n",
    "이전의 텍스처 전송 알고리즘은 텍스처 합성을 위해 이러한 비 파라 메트릭 방법을 사용하는 반면 대상 이미지의 구조를 보존하는 다양한 방법을 사용합니다.<br>\n",
    "예를 들어,<br>\n",
    "Efros와 Freeman은 텍스쳐 합성 절차를 제한하기 위해 이미지 강도와 같은 타겟 이미지의 특징을 포함하는 대응지도를 소개한다.<br>\n",
    "'Hertzman et al'은 이미지 유추를 사용하여 이미 양식이 붙은 이미지에서 대상 이미지로 텍스처를 전송합니다.<br>\n",
    "Ashikhmin은 대상 이미지의 거친 스케일을 유지하면서 고주파 텍스쳐 정보를 전송하는 것에 초점을 맞 춥니 다.<br>\n",
    "'Lee et al'은 에지 방향 정보로 텍스쳐 전송을 추가적으로 알려줌으로써이 알고리즘을 개선한다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비 모수적인 알고리즘들은 보여주는 결과는 그럴듯 하지만 근본적인 한계가 있습니다.\n",
    "\n",
    "### 대상의 저수준 정보만을 이용하며, 모델 하나가 적용 가능한 도메인도 극히 한정됩니다.\n",
    "\n",
    "### 본 논문에서 제시하는 모델은 수많은 파라미터를 기반으로 좀더 일반화 된 기능을 선보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이러한 알고리즘은 주목할만한 결과를 가져 오지만 모두 동일한 근본적인 한계를 겪습니다.<br>\n",
    "대상 이미지의 저급 이미지 기능 만 사용하여 텍스처 전송을 알립니다.<br>\n",
    "그러나 스타일 전송 알고리즘은 대상 이미지 (예 : 객체 및 일반적인 풍경)에서 의미 이미지 컨텐트를 추출 할 수 있어야하고, 텍스처 전송 절차에 알리고 스타일의 의미있는 내용을 렌더링 할 수 있어야합니다.<br>\n",
    "그러므로 의미있는 이미지 내용과 제시되는 스타일의 변형을 독립적으로 모델링하는 이미지 표현을 찾는 것이 근본적인 전제 조건입니다.<br>\n",
    "이러한 인자 화 된 표현은 상이한 조명 조건 하에서의 얼굴 및 상이한 폰트 스타일 또는 필기 자릿수 및 집 번호와 같은 자연 화상의 제어 된 서브 세트에 대해서만 이전에 달성되었다.<br>\n",
    "일반적으로 자연 이미지에서 스타일과 컨텐츠를 분리하는 것은 여전히 매우 어려운 문제입니다.<br>\n",
    "그러나, 최근의 Deep Convolutional Neural Networks의 진보는 자연 영상으로부터 높은 수준의 의미 정보를 추출하는 방법을 배우는 강력한 컴퓨터 비전 시스템을 만들어 냈습니다.<br>\n",
    "객체 인식과 같은 특정 작업에 대해 충분한 레이블이 지정된 데이터로 훈련 된 Convolutional Neural Networks는 텍스처 인식 및 예술적 스타일을 비롯한 기타 시각적 정보 처리 작업 및 데이터 세트 전반에 걸쳐 일반화 된 일반 기능 표현의 고급 이미지 콘텐츠를 추출하는 방법을 배웁니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 본 논문에서 제시하는 모델은 CNN을 활용해 텍스쳐 전송을 우아하게 최적화 문제로 탈바꿈합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이 연구에서는 고성능 Convolutional Neural Networks에서 습득 한 일반적인 특징 표현을 사용하여 자연 이미지의 내용과 스타일을 독립적으로 처리하고 조작하는 방법을 보여줍니다.<br>\n",
    "이미지 스타일 전송을 수행하는 새로운 알고리즘 인 Artistic Style의 Neural Algorithm을 소개합니다.<br>\n",
    "개념적으로 최첨단 컨볼 루션 뉴럴 네트워크 (Convolutional Neural Networks)의 특징 표현에 의한 텍스처 합성 방법을 제약하는 텍스처 전송 알고리즘입니다.<br>\n",
    "텍스쳐 모델은 딥 이미지 표현에 기반하기 때문에 스타일 전송 방법은 단일 뉴럴 네트워크 내에서 최적화 문제를 우아하게 줄입니다.<br>\n",
    "새 이미지는 예제 이미지의 피쳐 표현을 일치시키기 위해 사전 이미지 검색을 수행하여 생성됩니다.<br>\n",
    "이 일반적인 접근법은 텍스처 합성의 맥락에서 사용되었고 심층적 인 이미지 표현에 대한 이해를 향상시킵니다.<br>\n",
    "사실 우리의 스타일 전송 알고리즘은 컨볼 루션 뉴럴 네트워크 (Convolutional Neural Networks)에 기반한 파라메트릭 텍스처 모델과 이미지 표현을 반전시키는 방법을 결합합니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 위는 요약짤입니다.\n",
    "\n",
    "### 1. 인풋 이미지는 복수개의 필터링 된 이미지들로 처리됩니다.\n",
    "\n",
    "### 2. 인풋 이미지는 모델에 깊게 들어갈수록 더 많은 종류의 필터링 된 이미지로 처리되며, 동시에 그 크기가 작아집니다.\n",
    "#### - Downsampling 기법을 사용해 그 크기가 작아집니다. (ex. max-pooling, average-pooling)\n",
    "#### - 또한, 깊은 레이어일수록 해당 레이어 전체의 파라미터 수가 적어지는 구조입니다.\n",
    "\n",
    "### 3. 각 레이어에 존재하는 정보를 이용해 이미지 내용을 복원합니다. (Content reconstruction)\n",
    "#### - 깊이 내려갈수록 디테일한 픽셀 정보가 손실되는 것을 알 수 있습니다.\n",
    "#### - 하지만 어떤 내용이 이미지에 있는지는 보존되고 있습니다.\n",
    "\n",
    "### 4. 각 레이어에 존재하는 정보를 이용해 이미지의 스타일을 구축합니다. (Style reconstruction)\n",
    "#### - CNN의 각 레이어마다 그 상위에 Feature space에 적용되는 Operation을 하나 추가합니다.\n",
    "#### - 이 Operation은 각 Feature사이의 Correlation을 구합니다.\n",
    "#### - 자세한 원리는 후에 기술합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Overview\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제시된 논문의 결과물들은 VGG네트워크를 기반으로 만들어 졌습니다.\n",
    "\n",
    "### 사용된 VGG네트워크는 Localization과 객체 인식을 위해 사전 훈련된 모델입니다.\n",
    "\n",
    "### We used the feature space provided by a normalised version of the 16 convolutional and 5 pooling layers of the 19-layer VGG network\n",
    "\n",
    "### CNN에서 필터의 값들은 그 평균이 1이 되도록 Normalize 되었습니다.\n",
    "\n",
    "#### - 이런 방식의 단순 스케일링은 선형 오퍼레이션만 변형시키기 때문에 모델의 결과를 바꾸지 않습니다.\n",
    "\n",
    "### Max-pooling보다 Average-pooling이 더 보기좋은 결과를 만들었습니다.\n",
    "\n",
    "> 아래에 제시된 결과는 객체 인식 및 로컬라이제이션을 수행하도록 훈련 된 VGG 네트워크를 기반으로 생성되었으며 원래 작업에서 광범위하게 설명되었습니다.<br>\n",
    "우리는 19 계층 VGG 네트워크의 16 개 컨벌루션 및 5 풀링 레이어의 정규화 버전에서 제공되는 기능 공간을 사용했습니다.<br>\n",
    "이미지와 위치에 대한 각 컨벌루션 필터의 평균 활성화가 1과 같도록 가중치를 조정하여 네트워크를 표준화했습니다.<br>\n",
    "이러한 재조정은 VGG 네트워크의 출력을 변경하지 않고 수행 할 수 있습니다. 정교한 선형 활성화 기능 만 포함되고 기능 맵에 대한 정규화 또는 풀링이 없기 때문입니다.<br>\n",
    "우리는 완전히 연결된 레이어를 사용하지 않습니다.<br>\n",
    "이 모델은 대중적으로 이용 가능하며 caffe 프레임 워크에서 탐색 할 수 있습니다.<br>\n",
    "이미지 합성의 경우 최대 풀링 작업을 평균 풀링으로 대체하는 것이 약간 더 매력적인 결과를 산출하는 것으로 나타났습니다. 이것이 이미지가 평균 풀링으로 생성 된 이유입니다.<br>\n",
    "\n",
    "### 모델은 크게 세개의 개념으로 나눌 수 있습니다.\n",
    "#### 1-1. Content representation\n",
    "#### 1-2. Style representation\n",
    "#### 2. Style transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Content representation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 일반적으로 l레이어의 필터 수가 N개일 때, 이 레이어에서는 N개의 Feature map이 만들어집니다.\n",
    "\n",
    "### 이 경우 Feature map의 크기는 M입니다. (M은 세로 곱하기 가로)\n",
    "\n",
    "### 해당 레이어의 결과는 F로 축약되어 표현합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 레이어마다 이미지가 어떻게 인코딩 되었는지는 다릅니다.\n",
    "\n",
    "### 인코딩 된 이미지를 시각화(복원) 하는 과정은 SGD를 이용합니다.\n",
    "\n",
    "### 화이트 노이즈 상태의 이미지에서 시작해 원본컨텐츠 이미지와 같아지도록 학습합니다.\n",
    "\n",
    "### Squared-error 로스를 사용했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN이 객체 인식관점에서 학습하게 되면, 해당 객체를 명확히 구분짓는 특징을 학습하게 됩니다.\n",
    "\n",
    "### 따라서 신경망의 깊은 위치에 있을 수록, 디테일한 픽셀정보는 잃지만, 객체와 그 위치에 대한 높은 수준의 정보는 유지합니다.\n",
    "\n",
    "> 컨볼 루션 뉴럴 네트워크 (Convolutional Neural Networks)는 물체 인식에 대해 교육을 받으면 처리 계층을 따라 물체 정보를 더욱 명확하게 표현하는 이미지 표현을 개발합니다.<br>\n",
    "따라서 네트워크의 처리 계층 구조에 따라 입력 이미지는 이미지의 실제 내용에 점점 더 민감한 표현으로 변환되지만 정확한 모양에 상대적으로 변하지 않습니다.<br>\n",
    "따라서 네트워크의 상위 계층은 입력 이미지에서 객체와 그 배열과 관련하여 높은 수준의 내용을 캡처하지만 재구성의 정확한 픽셀 값을 크게 제한하지 않습니다 (그림 1, 내용 재구성 d, e).<br>\n",
    "대조적으로 하위 계층의 재구성은 원래 이미지의 정확한 픽셀 값을 단순히 재현합니다 (그림 1, 컨텐츠 재구성 a-c).<br>\n",
    "따라서 우리는 네트워크의 상위 계층에서 기능 응답을 컨텐츠 표현이라고합니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Style representation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본 이미지 (스타일)의 스타일 정보를 효과적으로 잡아내기 위한 Feature space를 만들기 위해 Operation을 추가합니다.\n",
    "\n",
    "### 이 Operation은 필터들로 인해 생긴 피쳐맵 위에서 동작합니다.\n",
    "\n",
    "### Operation의 핵심 과정은 각 피쳐간의 Correlation을 구하는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operation의 결과물로 Gram-matrix가 만들어집니다.\n",
    "\n",
    "[gram-matrix](https://ko.wikipedia.org/wiki/%EA%B7%B8%EB%9E%8C_%ED%96%89%EB%A0%AC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이 작업의 당위성은 다음과 같이 설명됩니다.\n",
    "\n",
    "#### 1. 스타일은 한 이미지에 전체적으로 고루 적용되어 있는 속성이다.\n",
    "\n",
    "#### 2. 그러니까 CNN으로부터의 모든 피쳐간에 상관관계가 높은 요소가 바로 스타일이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/10.png)\n",
    "![](./img/11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 레이어당 로스는 다음과 같이 간단한 Mean squared error 방식으로 정의됩니다.\n",
    "\n",
    "### w는 레이어마다 얼마나 영향력을 끼칠 지 결정하는 하이퍼파라미터입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Style transfer\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/5.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
