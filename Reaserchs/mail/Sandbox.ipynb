{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(i):\n",
    "    x = train_X[i]\n",
    "    img = x.reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TF_Agent():\n",
    "    \n",
    "    def __init__(self, keys):\n",
    "        self._initialize(keys)\n",
    "        \n",
    "    def _initialize(self, keys):\n",
    "        np.random.seed(0)\n",
    "        self.log_df = pd.DataFrame({key: [] for key in keys})\n",
    "        self.keys = self.log_df.columns\n",
    "        self.interesting = \",\".join(self.log_df.columns)\n",
    "        self.iter_count = 0     \n",
    "\n",
    "    def set_batch(self, n, feed_dict):\n",
    "        \n",
    "        keys = list(feed_dict.keys())\n",
    "        \n",
    "        data_n = len(feed_dict[keys[0]])\n",
    "        indices = np.random.choice(range(data_n), n, replace=False)\n",
    "        \n",
    "        feed_dict = {key: feed_dict[key][indices] for key in keys}\n",
    "        self.feed_dict = feed_dict\n",
    "    \n",
    "    def run_session(self, sess):\n",
    "        \n",
    "        values = sess.run(eval(self.interesting),\n",
    "                          feed_dict=self.feed_dict)\n",
    "        \n",
    "        self.recent_log = pd.Series(values, index=self.keys)\n",
    "        self.log_df.append([self.recent_log])\n",
    "        \n",
    "        self.iter_count += 1\n",
    "        \n",
    "    def trace(self, *args, one_line_text=\"\"):\n",
    "        \n",
    "        iter_count = self.iter_count\n",
    "        deco = [\"-\", \"\\\\\", \"|\", \"/\"][iter_count%4]\n",
    "        \n",
    "        one_line_text = \"Iter: % 6d\"%iter_count\n",
    "        for arg in args:\n",
    "            one_line_text += \" %s %s: %0.9f\"%(\n",
    "                deco, arg, self.recent_log[arg]\n",
    "            )\n",
    "\n",
    "        sys.stdout.write(\"\\r%s\"%one_line_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "g = tf.get_default_graph()\n",
    "\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 3*32*32])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, 3*32*32])\n",
    "\n",
    "enc_L1 = tf.contrib.layers.fully_connected(\n",
    "    X, 1024, activation_fn=tf.sigmoid\n",
    ")\n",
    "enc_L2 = tf.contrib.layers.fully_connected(\n",
    "    enc_L1, 256, activation_fn=tf.sigmoid\n",
    ")\n",
    "\n",
    "mid_L = tf.contrib.layers.fully_connected(\n",
    "    enc_L2, 64, activation_fn=tf.sigmoid\n",
    ")\n",
    "\n",
    "dec_L1 = tf.contrib.layers.fully_connected(\n",
    "    mid_L, 256, activation_fn=tf.sigmoid\n",
    ")\n",
    "dec_L2 = tf.contrib.layers.fully_connected(\n",
    "    dec_L1, 1024, activation_fn=tf.sigmoid\n",
    ")\n",
    "\n",
    "output = tf.contrib.layers.fully_connected(\n",
    "    dec_L2, 3*32*32, activation_fn=tf.sigmoid\n",
    ")\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(Y, output)\n",
    "learn = tf.train.AdadeltaOptimizer().minimize(loss)\n",
    "\n",
    "initializer = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(\"./data/data_batch_1\")\n",
    "train_X = dataset[\"data\"]\n",
    "train_y = dataset[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:   1000 - ['loss']: 2895347.500000000"
     ]
    }
   ],
   "source": [
    "tfa = TF_Agent([\"loss\", \"learn\"])\n",
    "sess = tf.Session(graph=g)\n",
    "sess.run(initializer)\n",
    "for i in range(1000):\n",
    "    tfa.set_batch(100, {X: train_X, Y: train_X})\n",
    "    tfa.run_session(sess)\n",
    "    tfa.trace([\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
