{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016년 1월 10일 논문\n",
    "\n",
    "##  Goals\n",
    "\n",
    "- ### semi-supervised learning\n",
    "\n",
    "    > - ### 레이블이 표시된 데이터와 표시되지 않은 데이터를 모두 훈련에 사용하는 것\n",
    "\n",
    "    - ### 다음의 데이터를 분류하는 작업에서 SOTA\n",
    "\n",
    "        - ### MNIST\n",
    "        - ### CIFAR-10\n",
    "        - ### SVHN\n",
    "\n",
    "\n",
    "- ### 사실적인 이미지 생성\n",
    "\n",
    "    - ### 생성 된 이미지는\n",
    "\n",
    "        - ### Visual 튜링 테스트를 통과할 정도로 고품질\n",
    "        - ### 인간이 실제 데이터와 구별 할 수 없는 MNIST 샘플을 생성\n",
    "        - ### CIFAR-10 샘플에서 21.3%의 Human error rate(?)\n",
    "        - ### 전례없이 고화질의 ImageNet 샘플을 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN\n",
    "\n",
    "- ### GAN의 목표\n",
    "\n",
    "    - ### $p_{data}(x)$\n",
    "    - ### $x = G(z;\\theta^{(G)})$\n",
    "\n",
    "- ### $G$의 학습\n",
    "\n",
    "    - ### $D(x)$에 의해 학습\n",
    "    - ### $D(x)$는 $x$가 $p_{model}(x)$와 $p_{data}(x)$중 어디서 생긴 건지 구분\n",
    "    - ### $G$는 $D$가 잘 구분하지 못하도록 학습됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN의 잠재적인 약점\n",
    "\n",
    "- ### 수많은 사례로 GAN이 끝내주는 샘플을 만들어 낼 수 있다는게 증명되고 있음.\n",
    "\n",
    "- ### GAN은 non-convex, 고차원, 연속공간 모수들에서 내쉬균형을 찾아내야 함.\n",
    "\n",
    "> - ### 내쉬 균형(Nash equilibrium)은 게임 이론에서 경쟁자 대응에 따라 최선의 선택을 하면 서로가 자신의 선택을 바꾸지 않는 균형상태를 말한다.\n",
    "\n",
    "> - ### GAN은 게임 이론을 기반으로 생성 모델을 학습하는 방법의 한 종류이다.\n",
    "\n",
    "- ### 하지만 GAN의 학습은 SGD를 이용함. 이는 내쉬균형을 찾는것을 보장하지 못함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN이 수렴하도록 하기 위한 몇가지 기술을 제시\n",
    "\n",
    "- ### 이 기술들은 비수렴 문제의 경험적 이해에 의해 제시됨.\n",
    "- ### 더 나은 Semi-supervised learning과 더 나은 표본 생성을 위해 제시됨.\n",
    "- ### 제시된 기술들이 효과적이란게 엄밀히 증명되어 널리 쓰이길 바람...\n",
    "- ### 코드도 제공... [https://github.com/openai/improved-gan](https://github.com/openai/improved-gan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Related word\n",
    "\n",
    "```python\n",
    "pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Toward Convergent GAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN은 2인-비협조-게임에 대한 내쉬 균형을 찾는 것이다.\n",
    "\n",
    "## 각 플레이어는 자신들의 비용함수를 최소화하고자한다.\n",
    "\n",
    "- ### $D$입장에서 비용함수: $J^{(D)}(\\theta^{(D)},\\theta^{(G)})$\n",
    "\n",
    "- ### $G$입장에서 비용함수: $J^{(G)}(\\theta^{(D)},\\theta^{(G)})$\n",
    "\n",
    "- ### 내쉬균형 $(\\theta^{(D)},\\theta^{(G)})$을 찾자\n",
    "\n",
    "    > - ### $J^{(D)}$는 $\\theta^{(D)}$에 대해 최소\n",
    "    > - ### $J^{(G)}$는 $\\theta^{(G)}$에 대해 최소\n",
    "    \n",
    "## 사실 내쉬균형을 찾는건 매우 어려운 일이다.\n",
    "\n",
    "- ### 특별한 케이스에 대해서는 풀이방법이 있지만\n",
    "\n",
    "- ### GAN의 경우에 적용되는 풀이법은 없다.\n",
    "\n",
    "- ### GAN의 경우는 Non-convex이고 연속공간의 (매우)고차원의 모수를 대상으로 한다.\n",
    "\n",
    "## 왜 어렵냐면,\n",
    "\n",
    "- ### 각 플레이어가 자신의 코스트를 최소화하면서 내쉬균형에 가까워진다는 생각은 직관적으로 말이 되는듯 하지만,\n",
    "- ### $J^{(G)}$를 줄이기 위한 $\\theta^{(G)}$의 변화가 $J^{(D)}$를 증가시킬 수 있다.\n",
    "- ### $J^{(D)}$를 줄이기 위한 $\\theta^{(D)}$의 변화가 $J^{(G)}$를 증가시킬 수 있다.\n",
    "    > - ### 박재범이 xy를 줄이기 위해 x를 움직이고\n",
    "    > - ### 지코가 -xy를 줄이기 위해 y를 움직이면\n",
    "    > - ### 이상적인 수렴은 $x = y = 0$인데,\n",
    "    > - ### SGD는 수렴하지 않고 궤도를 돌게 된다.\n",
    "\n",
    "## 이를 해결하기 위해 논문에서 몇가지 기술을 제시한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Feature matching\n",
    "\n",
    "### Feature matching은 Generator가 (당시의)Discriminator에서 과하게 학습하지 않도록 하는 것\n",
    "### (사견) Overfitting을 피하는 느낌으로 생각해도 괜찮을것 같다\n",
    "### 목적함수가 다음과 같이 변한다.\n",
    "- ### $|| E_{x\\tilde{}p_{data}}f(x) - E_{z\\tilde{}p_{z}(z)}f(G(z)) ||^2_2$\n",
    "- ### $f(x)$는 $D$의 뉴런 중간쯤에 있는 레이어의 피쳐값을 의미한다.\n",
    "- ### 기존에는 $f(x)$대신 $D(x)$를 이용했음을 주목.\n",
    "- ### 이로써 Discriminator가 유의미하다고 생각하는 피쳐에만 집중해 Generator의 학습이 이루어진다.\n",
    "\n",
    "### 이렇게 하면 좀더 나은 결과를 보이는 경향이 있다고 한다.\n",
    "> - ### (사견) 그냥 노이즈를 효과적으로 줄이면서 파라미터 개수도 줄었기 때문에 => 모델 복잡도도 줄고 => 내쉬균형으로의 근사를 방해할 요소도 줄어들 확률이 커져서 => 더 좋아지는 걸수도 있을 것같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Minibatch discrimination\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN 붕괴\n",
    "\n",
    "- ### G가 어떤 z에 대해서든 항상 같은 값을 생성하도록 모수들이 설정되는 경우가 발생\n",
    "- ### G가 계속 비슷한 값들을 생성하는 경우.. D도 계속 비슷한 방향을 가리키는 비용을 전파..\n",
    "- ### D는 각각의 단계마다 그저 독립적으로 비용을 계산\n",
    "- ### 따라서 G가 다양한 값을 출력하도록 하는 메커니즘이 전혀 없음\n",
    "- ### 결과적으로 G는 그저 D가 진짜라고 믿는 한개의 점으로 수렴해버림\n",
    "- ### 다음 단계에서 D는 G가 출력하는 점이 거짓이란걸 알아버림\n",
    "- ### SGD알고리즘은 이미 한점에 수렴하게 된 모델을 다시 쪼개는 능력은 없음\n",
    "- ### G는 영원히 수렴하지 못하고 공간을 떠도는 점을 출력하게 됨\n",
    "- ### G는 필요한 만큼의 엔트로피(정보량)를 가지지 못하는 모델이 되어버림\n",
    "\n",
    "## Minibatch\n",
    "\n",
    "- ### 한번에 한개의 예제로 학습하지 말고 여러개 예제의 조합으로 학습하기\n",
    "- ### 배치놈의 성공이 이러한 관점에서 설명될 수도 있다..\n",
    "\n",
    "## Minibatch 자세히\n",
    "\n",
    "- ### $f(x_i)$는 D의 레이어중 하나에서 가져온 피쳐\n",
    "- ### $f(x_i) \\in R^{A}$\n",
    "- ### $T \\in R^{A \\times B \\times C}$\n",
    "- ### $M_i \\in R^{B \\times C}$\n",
    "- ### $c_b(x_i, x_j) = exp(-|| M_{i, b} - M_{j, b} ||_{L1}) \\in R$\n",
    "![](./img/1.png)\n",
    "![](./img/2.png)\n",
    "- ### $f(x_i)와 o(x_i)$를 Concatenate해서 D의 다음 레이어에 넘긴다.\n",
    "- ### D는 여전히 진짜와 가짜를 구분하는 역할을 한다.\n",
    "- ### D는 이번에는 데이터가 평균 군집보다 얼마나 떨어져 있는지에 대한 추가 정보를 가지고 구분한다.\n",
    "\n",
    "## 일반적으로 Minibatch 를 이용하면 빨리 Visually appealing이미지를 만들어 낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Historical averaging\n",
    "\n",
    "## $|| \\theta - \\frac{1}{t}\\sum^{t}_{i=1}\\theta[i] ||^2$\n",
    "\n",
    "- ### 위 Term을 비용함수에 추가\n",
    "- ### $i$시점 전을 의미\n",
    "- ### 저차원 Non-convex의 경우 유용함\n",
    "- ### 예를 들어 Minimax 값을 찾는 경우...\n",
    "    - ### $(x-1)(y-1)$\n",
    "    - ### $x < 0$\n",
    "    - ### 이때 일반적인 경우, 수렴 못하고 궤도를 떠돌게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 One-sided label smoothing\n",
    "\n",
    "\n",
    "- ### 1980년에 만들어진 기술인데, 재조명 받고있음\n",
    "- ### {0, 1} 레이블을 {0.1, 0.9}로 바꿔서 사용하는 것..\n",
    "\n",
    "## $D(x) = \\frac{\\alpha p_{data}(x)+\\beta p_{model}(x)}{p_{data}(x)+p_{model}(x)}$\n",
    "\n",
    "- ### 적용하면 위와 같이 D가 변함\n",
    "- ### $\\alpha$는 기존의 레이블 1\n",
    "- ### $\\beta$는 기존의 레이블 0\n",
    "\n",
    "## One-sided\n",
    "- ### 분자에 $p_{model}$이 남아있는건 문제의 여지가 많다.\n",
    "- ### $p_{data}$가 작고 $p_{model}$이 큰 경우 문제가 됨\n",
    "- ### $p_{model}$이 잘 근하사고 있다는 보장도 없고 이를 G에게 비용으로 전파하는 것도 넌센스\n",
    "- ### 따라서 $\\alpha$만 0.9쯤으로 바꾸고 $\\beta$는 0으로 그대로 둠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual batch normalization\n",
    "\n",
    "## Batch normalization\n",
    "- ### 좋은 기술, DCGAN과 궁합이 잘맞는다.\n",
    "- ### 그러나 인풋 $x$가 같은 배치 안의 $x^{\\prime}$에 영향 받는다는 단점이 있음\n",
    "\n",
    "## Virtual batch normalization\n",
    "![](./img/3.png)\n",
    "![](./img/4.png)\n",
    "- ### reference batch를 이용함\n",
    "- ### reference batch는 자기들끼리의 통계량으로 전파됨\n",
    "- ### 따라서 두개의 batch normalization연산을 쭉 해나가야하므로 계산비용이 높음\n",
    "- ### 계산비용이 높아서 G에만 써줬다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Assessment of image quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/6.png)\n",
    "![](./img/7.png)\n",
    "\n",
    "## Inception model\n",
    "\n",
    "- ### 사람이 평가하는 방식에 대한 대안\n",
    "- ### 사람의 평가와 상관계수가 높았음\n",
    "- ### 모든 생성된 이미지에 대해 $p(y|x)$를 구함\n",
    "- ### 만약 이미지가 잘 만들어졌다면 $p(y|x)$는 낮은 엔트로피를 가져야함\n",
    "- ### 모델은 주어진 잠재변수 $z$에 대해 다양한 사진을 만들어야함\n",
    "- ### 따라서 $\\int p(y|x = G(z))dz$는 높은 엔트로피를 가져야함\n",
    "- ### 이 방식은 CatGAN에서 G를 학습하기 위해 이용한 목적함수와 비슷한 컨셉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Semi-supervised learning\n",
    "\n",
    "### 배경설명\n",
    "- ### $x$를 $K$개의 가능한 클래스중 하나로 분류하는 D\n",
    "- ### Softmax를 이용하면 D의 아웃풋은 K차원의 확률값들이 됨\n",
    "\n",
    "### Semi-supervised\n",
    "- ### G에서 만든 샘플도 D에 적용할 수 있음\n",
    "- ### 이때 $K$차원이 아닌 $K+1$차원으로 적용함\n",
    "- ### 더해진 차원은 $x$가 가짜일 확률을 의미함\n",
    "\n",
    "![](./img/5.png)\n",
    "![](./img/8.png)\n",
    "\n",
    "- ### Supervised loss의 k+1차원은 무조건 0으로 둠\n",
    "\n",
    "### 문제\n",
    "- ### 이런식으로 Semi-supervised learning을 하는 경우가 항상 도움이 되는건 아님\n",
    "- ### 연구 대상이 되는 데이터가 엄청 복잡해야함 (못찾는 부분을 얻어 걸려야하니까)\n",
    "- ### Feature matching 기술을 이용하면 잘됨\n",
    "- ### Minibatrch 기술을 이용하니까 망함\n",
    "- ### 왜그런지는 연구해서 알아내겠다고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Experiments\n",
    "\n",
    "![](./img/9.png)\n",
    "![](./img/10.png)\n",
    "![](./img/11.png)\n",
    "![](./img/12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
