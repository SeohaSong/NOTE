{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "- 장기기억 모듈과 추론 모듈의 결합\n",
    "- 장기기억과 추론을 결합해 사용하는 방법을 배우는 네트워크\n",
    "- 장기기억이 예측에서도 이용될 수 있다.\n",
    "- knowledge base 모델처럼 long-term memory가 이용될 수 있다.\n",
    "- 위에대한 성능 평가를 위해 질문-응답 테스트에 대해 네트워크의 성능을 조사했다.\n",
    "- 학습한 문장들을 기반으로 질문 내용을 이해하는 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "1. 대부분의 기계학습은 메모리를 읽고 쓰는 능력의 결여, 알고리즘(패턴인식)과 저장장치 사이에 자연스러운 연결이 없음\n",
    "\n",
    "2. 결국 현대 컴퓨터인 튜링머신에서 메모리 부분을 제대로 이용하지 못하고 있음 (기억장치에 읽고 쓰는 기능)\n",
    "\n",
    "3. 메모리는 지능에서 중요한 요소입니다. Knowledge base된 의사결정을 내릴 수 있게 돕습니다.\n",
    "\n",
    "### 일련의 사실이나 이야기를 듣고난 뒤 질문에 대답하는 Task\n",
    "\n",
    "1. 일반적으로 이런 작업에는 RNN이 적합하다고 여겨짐. (Sequence to sequence)\n",
    "2. 그러나 신경망의 은닉노드만으로는 기억할 수 있는 정도가 너무 적다.\n",
    "3. 또한 과거의 사실을 정확히 기억할 수 있도록 잘 구분되어 저장되지도 않는다. (데이타가 밀도 높은 백터로 압축되어버린다.)\n",
    "4. RNN은 단순 암기조차 수행하기 힘들다는게 논문으로 논의됨.\n",
    "5. 비디오 또는 사진들을 보고 그것에 대답하기 위해 더 많은 메모리가 필요하다.\n",
    "\n",
    "### 이러한 문제를 해결하기 위한 메모리 네트워크\n",
    "\n",
    "1. 기계학습에서 추론을 담당하는 모듈과 메모리 구성요소를 결합한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memoty Networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메모리 네트워크는 다음의 요소로 구성\n",
    "\n",
    "### $m$: 메모리\n",
    "> 객체들의 배열. $m_i$로 인덱싱\n",
    "\n",
    "### $I$: Intput feature map\n",
    "> 인풋을 내부의 피처 표현방식으로 변환 (백터화?)\n",
    "\n",
    "### $G$: Generalization \n",
    "> 새로운 입력에 따라 오래된 기억을 업데이트함. 일반화라 불리는 이유는 기억을 추후 사용하기 위해 기억을 압축하고 일반화할 수 있는 단계이기 때문.\n",
    "\n",
    "### $O$: Output feature map\n",
    "> 백터공간에서의 출력\n",
    "\n",
    "### $R$: Response\n",
    "> 아웃풋을 우리가 원하는 형태로 출력\n",
    "\n",
    "1. 인풋 $x$ (단어 또는 문장, 이미지 또는 오디오 신호)\n",
    "\n",
    "2. $x$를 내부의 피처 표현(백터같은) $I(x)$로 변환\n",
    "\n",
    "3. 메모리 $m_i$를 업데이트함. $m_i = G(m_i, I(x), m), \\forall i$\n",
    "\n",
    "4. 인풋과 메모리를 이용해 아웃풋을 계산 $o = O(I(x), m)$\n",
    "\n",
    "5. 아웃풋을 원하는 표현방식으로 변환 $r = R(o)$\n",
    "\n",
    "이 과정이 학습과 테스트 모두에 적용됨.\n",
    "\n",
    "적용시 테스트 과정에서는 m만 업데이트하고 $I, G, O, R$은 변하지 않는다.\n",
    "\n",
    "$I, G, O, R$ 꼭 신경망이 아니어도 어떤 모델이든 적용 가능하다. (서포트벡터머신, 의사결정나무 등)\n",
    "\n",
    "## Detail\n",
    "\n",
    "### $I$\n",
    "\n",
    "컴포넌트 $I$은 텍스트 입력을위한 파싱 (parsing), 코어 레퍼런스 (coreference) 및 엔티티 (entity) 해상도와 같은 표준 전처리를 이용할 수있다.\n",
    "\n",
    "또한 입력을 내부의 백터공간으로 바꾸는 역할을 한다.\n",
    "\n",
    "### $G$\n",
    "\n",
    "$G$는 변환된 인풋 $I(x)를 메모리에 저장한다.$\n",
    "\n",
    "![](img/1.png)\n",
    "\n",
    "$H(.)$는 리스트의 인덱스 선택 위한 알고리즘을 의미 (아웃풋이 $i$)\n",
    "\n",
    "더 복잡하게 확장해서 다수의 인덱스를 탐색할 수도 있고,\n",
    "\n",
    "현재 정보에 기반해 예전 인덱스를 업데이트 할 수도 있음.\n",
    "\n",
    "인풋이 단어처럼 그룹화가 가능한 경우 모아서 한 슬롯에 저장가능 (청킹)\n",
    "\n",
    "저장하는 방식도 나중에 탐색이 용이하도록 다양하게 응용함\n",
    "\n",
    "메모리가 일정 수준 이상이 되면 망각하도록 디자인 가능 (마치 쓸모없는 프로그램을 찾아서 지우는것처럼)\n",
    "\n",
    "### $O, R$\n",
    "\n",
    "$O$는 메모리를 읽고 추론하는 부분.\n",
    "\n",
    "메모리의 어떤 부분이 대답과 관련된 부분인지 계산.\n",
    "\n",
    "$R$은 $O$가 선택한 메모리들에 대해 최종 결과물을 계산.\n",
    "\n",
    "예를들면, $O$의 아웃풋들을 인풋으로 받는 RNN일 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A MEMNN IMPLEMENTATION FOR TEXT\n",
    "\n",
    "메모리 네트워크에서 뉴럴넷을 쓰면 MemNNs라고 부름.\n",
    "\n",
    "인풋도 텍스트 아웃풋도 텍스트인 예시를 보자. (대신 아웃풋은 단어 1개가 되도록 제한)\n",
    "\n",
    "![](img/2.png)\n",
    "\n",
    "위 문제를 풀기 위해 서포팅 메모리의 개수를 2개로 놓자. $k=2$\n",
    "\n",
    "추론을 담당하는 핵심 부분은 $O, R$은 비슷한 원리로 동작한다.\n",
    "\n",
    "![](img/3.png)\n",
    "![](img/4.png)\n",
    "![](img/5.png)\n",
    "\n",
    "\n",
    "### $x$  => “Where is the milk now?”\n",
    "### $m_{o1}$ => “Joe left the milk”\n",
    "### $m_{o2}$ => “Joe travelled to the office” \n",
    "### $r$ =>  “office”\n",
    "\n",
    "![](img/6.png)\n",
    "\n",
    "![](img/7.png)\n",
    "\n",
    "## Training\n",
    "\n",
    "### Loss function\n",
    "\n",
    "![](img/8.png)\n",
    "\n",
    "![](img/9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word sequence as input\n",
    "\n",
    "> 어떻게 청킹할지도 정해지지 않은 (어디까지가 한개의 질문으로 볼 수 있는지) 일련의 단어들이 인풋일 때, 다음과 같은 선형 분류 segmenter가 이용됩니다.\n",
    "\n",
    "![](img/10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient memory via hashing\n",
    "\n",
    "리스트 안에 모든 메모리를 담으면 탐색시간이 너무 오래 걸리므로 해쉬를 사용\n",
    "\n",
    "![](img/11.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
